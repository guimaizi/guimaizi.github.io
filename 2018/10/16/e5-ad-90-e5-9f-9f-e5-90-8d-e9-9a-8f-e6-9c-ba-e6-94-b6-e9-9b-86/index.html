<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta name="theme-color" content="#33474d">
	<title>子域名随机收集 | guimaizi&#39;s blog</title>
	<link rel="stylesheet" href="/css/style.css" />
	
      <link rel="alternate" href="/atom.xml" title="guimaizi&#39;s blog" type="application/atom+xml">
    
<meta name="generator" content="Hexo 4.2.0"></head>

<body>

	<header class="header">
		<nav class="header__nav">
			
				<a href="/archives" class="header__link">Archive</a>
			
				<a href="/tags" class="header__link">Tags</a>
			
				<a href="/atom.xml" class="header__link">RSS</a>
			
		</nav>
		<h1 class="header__title"><a href="/">guimaizi&#39;s blog</a></h1>
		<h2 class="header__subtitle">道心不改,灵台无尘。</h2>
	</header>

	<main>
		<article>
	
		<h1>子域名随机收集</h1>
	
	<div class="article__infos">
		<span class="article__date">2018-10-16</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/%E5%AE%89%E5%85%A8-%E4%BB%A3%E7%A0%81/">安全/代码</a>
			</span><br />
		
		
	</div>

	

	
		<blockquote>
<p>取随机数随机组合出(0-9 a-z .)字符串，dns穷举子域名<br>需要环境python3.5+ mongodb、别的自己pip install *<br>本来是异步的、但是requests会阻塞就线程了。<br>超时时间和线程数识网络环境自己设置</p>
</blockquote>
<pre><code># coding: utf-8
&apos;&apos;&apos;
Created on 2018年10月15日

@author: guimaizi
&apos;&apos;&apos;
import dns.resolver,requests,random,queue,time,threadpool
from pymongo import MongoClient
from bs4 import BeautifulSoup
class start:
    def __init__(self,domain):
        &apos;&apos;&apos;
        :domian 子域名收集
        &apos;&apos;&apos;
        self.domain=domain
        #超时
        self.timeout=5
        #线程数
        self.thread_num=100
        self.domain_list=[]
        self.result=[]
        #每次任务标记
        self.random=self.generate_random_str(16)
    def generate_random_str(self,randomlength):
        &quot;&quot;&quot;
        :randomlength 生成一个指定长度的随机字符串
        &quot;&quot;&quot;
        random_str = &apos;&apos;
        base_str = &apos;abcdefghigklmnopqrstuvwxyz0123456789.&apos;
        length = len(base_str) - 1
        for i in range(randomlength):
            random_str += base_str[random.randint(0, length)]
        return random_str

    def query(self,domain):
        &apos;&apos;&apos;
        dns查询存在域名
        &apos;&apos;&apos;
        myResolver = dns.resolver.Resolver()
        myResolver.nameservers = [&apos;8.8.8.8&apos;, &apos;8.8.4.4&apos;]

        try:
                myAnswers = myResolver.query(domain, &quot;A&quot;)
                self.domain_list.append(domain)
        except Exception as e:print(e)
    def get_http(self,domain):
        &apos;&apos;&apos;
        http获取:
        {&quot;domain&quot;:domain,&quot;url&quot;:target_url,&quot;status_code&quot;:&quot;%s&quot;%str(r.status_code),&quot;size_html&quot;:len(r.text),&quot;title&quot;:&quot;%s&quot;%str(self.get_title(r.text)),&quot;mark&quot;:self.random,&quot;time&quot;:time.strftime(&apos;%Y-%m-%d&apos;,time.localtime())}
        &apos;&apos;&apos;
        try:
            kv={&apos;user_agent&apos;:&apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36&apos;}
            target_url=&apos;http://&apos;+domain
            r = requests.get(target_url,headers=kv,timeout=self.timeout)
            r.encoding=&apos;utf-8&apos;
            data={&quot;domain&quot;:domain,&quot;url&quot;:target_url,&quot;status_code&quot;:&quot;%s&quot;%str(r.status_code),&quot;size_html&quot;:len(r.text),&quot;title&quot;:&quot;%s&quot;%str(self.get_title(r.text)),&quot;mark&quot;:self.random,&quot;time&quot;:time.strftime(&apos;%Y-%m-%d&apos;,time.localtime())}
            print(data)
            self.result.append(data)
        except Exception as e:print(e)
    def get_title(self,html):
        &apos;&apos;&apos;
        返回title
        &apos;&apos;&apos;
        try:
            soup = BeautifulSoup(html, &apos;html5lib&apos;)
            title = soup.find(&apos;title&apos;)
            return title
        except:
            return &apos;not&apos;
    def save_result(self,data_list):
        &apos;&apos;&apos;
        #保存数据
        :filename 文件路径及文件名
        :data_list list数据
        &apos;&apos;&apos;
        domain=self.domain.replace(&apos;.&apos;,&apos;_&apos;)
        f=open(&apos;%s.txt&apos;%domain,&apos;a&apos;,encoding=&apos;utf-8&apos;)
        for i in data_list:
            f.write(&apos;%s\n&apos;%str(i))
        f.close()
    def threadpool_fun(self,fun,lists,num):
        &apos;&apos;&apos;
        thread多线程池

        :fun 函数
        :lists 数据
        :num 线程数
        &apos;&apos;&apos;
        q = queue.Queue()
        for i in lists:
            q.put(i)
        lst = [q.get() for i in range(q.qsize())]
        pool = threadpool.ThreadPool(num)
        requestss = threadpool.makeRequests(fun, lst)
        [pool.putRequest(req) for req in requestss]
        pool.wait()
        pool.dismissWorkers(num, do_join=True) 
    def run(self,list_str):
        #去重
        client = MongoClient(&quot;localhost&quot;, 27017)
        db_target_domian = client.domian
        domain=self.domain.replace(&apos;.&apos;,&apos;_&apos;)
        collection =db_target_domian[domain]
        list_domain=[]
        for i in list_str:
            i=i+&apos;.&apos;+self.domain
            if collection.find({&quot;domain&quot;: &quot;%s&quot;%i}).count()==0:
                list_domain.append(i)
        print(list_domain)
        #运行
        self.threadpool_fun(self.query, list_domain, self.thread_num)
        time.sleep(self.timeout)
        self.threadpool_fun(self.get_http, self.domain_list, self.thread_num)
        #写入数据
        collection.insert(self.result,manipulate=True)
        time.sleep(self.timeout)
        #self.save_result(self.result)
    def random_str(self):
        list_str=[]
        for i in range(1000):
            list_str.append(self.generate_random_str(random.randint(1,10)))
        #运行
        self.run(list(set(list_str)))
if __name__==&quot;__main__&quot;:
    while 1:
        try:
            item=start(&apos;qq.com&apos;) 
            item.random_str()
        except:continue</code></pre><p><figure class="figure"><img src="https://s1.ax1x.com/2018/10/16/iaqI41.png" alt="iaqI41.png"><figcaption class="figure__caption">iaqI41.png</figcaption></figure></p>

	

	
		<span class="different-posts"><a href="/2018/10/16/e5-ad-90-e5-9f-9f-e5-90-8d-e9-9a-8f-e6-9c-ba-e6-94-b6-e9-9b-86/" onclick="window.history.go(-1); return false;">⬅️ Go back </a></span>

	

</article>

	</main>

	<footer class="footer">
	<div class="footer-content">
		
	      <div class="footer__element">
	<p>Hi there, <br />welcome to my Blog glad you found it. Have a look around, will you?</p>
</div>

	    
	      <div class="footer__element">
	<h5>Check out</h5>
	<ul class="footer-links">
		<li class="footer-links__link"><a href="/archives">Archive</a></li>
		
		  <li class="footer-links__link"><a href="/atom.xml">RSS</a></li>
	    
		<li class="footer-links__link"><a href="/about">about page</a></li>
		<li class="footer-links__link"><a href="/tags">Tags</a></li>
		<li class="footer-links__link"><a href="/categories">Categories</a></li>
	</ul>
</div>

	    

		<div class="footer-credit">
			<span>© 2020 guimaizi | Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> | Theme <a href="https://github.com/HoverBaum/meilidu-hexo" target="_blank" rel="noopener">MeiliDu</a></span>
		</div>

	</div>


</footer>



</body>

</html>
